[tool.poetry]
name = "quantizeeffinet"
version = "0.0.2b2"
description = "A simple package for converting TensorFlow Efficientnet models to ONNX and TensorRT formats."
authors = ["Zolta Gombar <gombarzolta@gmail.com>"]
readme = "README.md"
license = "Apache-2.0"
keywords = ["tensorflow", "onnx", "tensorrt", "model-conversion", "deep-learning", "machine-learning"]
repository = "https://github.com/zotyag/quantizeeffinet"

[tool.poetry.dependencies]
python = ">=3.8,<4.0"
tensorflow = "*"
tf2onnx = "*"
onnx = "*"
onnxconverter-common = "*"
tensorrt = "*"
numpy = "*"
pillow = "*"
cuda-python = "*"
protobuf = "~3.20.3"

[tool.poetry.group.test.dependencies]
pytest = [
    {version = "^8.3", python = ">=3.8,<3.10"},
    {version = "^9.0", python = ">=3.10"}
]

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[project]
name = "quantizeeffinet"
version = "0.0.2b2"
description = "A simple package for converting TensorFlow Efficientnet models to ONNX and TensorRT formats."
authors = [
    { name="Zolta Gombar", email="gombarzolta@gmail.com" }
]
readme = "README.md"
requires-python = ">=3.8"
license = {text = "Apache-2.0"}
keywords = ["tensorflow", "onnx", "tensorrt", "model-conversion", "deep-learning", "machine-learning"]

[project.urls]
Repository = "https://github.com/zotyag/quantizeeffinet"